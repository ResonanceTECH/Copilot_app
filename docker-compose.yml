version: '3.8'

services:
  db:
    image: postgres:15-alpine
    container_name: copilot_db
    environment:
      POSTGRES_USER: copilot_user
      POSTGRES_PASSWORD: copilot_pass
      POSTGRES_DB: copilot_db
    ports:
      - "5431:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/app/database/init.sql:/docker-entrypoint-initdb.d/01-init.sql
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U copilot_user"]
      interval: 10s
      timeout: 5s
      retries: 5

  whisper:
    image: onerahmet/openai-whisper-asr-webservice:latest
    container_name: copilot_whisper
    ports:
      - "9000:9000"
    environment:
      - ASR_MODEL=${WHISPER_MODEL_SIZE:-base}
      - ASR_ENGINE=faster_whisper
    volumes:
      - whisper_models:/app/models
    restart: unless-stopped
    healthcheck:
      # Проверяем доступность через корневой путь (сервис возвращает 307 редирект на /docs)
      test: ["CMD-SHELL", "python3 -c 'import urllib.request; urllib.request.urlopen(\"http://localhost:9000/\", timeout=5)' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    # Раскомментируйте секцию deploy ниже, если у вас есть GPU
    # Для CPU-only режима оставьте секцию deploy закомментированной
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  ollama:
    image: ollama/ollama:latest
    container_name: copilot_ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    restart: unless-stopped
    healthcheck:
      # Проверяем доступность API через простой endpoint
      test: ["CMD", "ollama", "list"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    # Раскомментируйте секцию deploy ниже, если у вас есть GPU
    # Для CPU-only режима оставьте секцию deploy закомментированной
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  app:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: copilot_app
    ports:
      - "8000:8000"
    environment:
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - DATABASE_URL=postgresql://copilot_user:copilot_pass@db:5432/copilot_db
      - OLLAMA_API_URL=http://ollama:11434
      - USE_OLLAMA=${USE_OLLAMA:-false}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-deepseek-r1-distill-llama}
      - WHISPER_API_URL=http://whisper:9000
      - USE_WHISPER_CONTAINER=${USE_WHISPER_CONTAINER:-false}
    env_file:
      - .env
    volumes:
      # Монтируем код для разработки (можно закомментировать для продакшена)
      - ./backend:/app/backend
      # Кэш для моделей Whisper (сохраняется между перезапусками)
      - whisper_cache:/root/.cache/huggingface
    depends_on:
      db:
        condition: service_healthy
      whisper:
        condition: service_healthy
      ollama:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/api/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

volumes:
  postgres_data:
  whisper_cache:
  whisper_models:
  ollama_models:

