from openai import OpenAI
import os
from dotenv import load_dotenv
from typing import List, Dict, Optional
import tiktoken
import httpx
import io

load_dotenv()


class LLMService:
    def __init__(self):
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç—ã –¥–ª—è –º–µ–¥–ª–µ–Ω–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
        timeout = httpx.Timeout(60.0, connect=30.0)  # 60 —Å–µ–∫ –Ω–∞ –∑–∞–ø—Ä–æ—Å, 30 —Å–µ–∫ –Ω–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
        http_client = httpx.Client(timeout=timeout)
        
        self.client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=os.getenv("OPENROUTER_API_KEY"),
            http_client=http_client
        )
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Whisper: –ª–æ–∫–∞–ª—å–Ω—ã–π –∏–ª–∏ API
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π Whisper, –µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω USE_WHISPER_API=true - –∏—Å–ø–æ–ª—å–∑—É–µ–º API
        use_whisper_api = os.getenv("USE_WHISPER_API", "false").lower() == "true"
        
        self.local_whisper = None
        self.whisper_client = None
        
        if use_whisper_api:
            # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Whisper API —á–µ—Ä–µ–∑ OpenAI
            openai_api_key = os.getenv("OPENAI_API_KEY")
            if openai_api_key:
                whisper_timeout = httpx.Timeout(120.0, connect=30.0)  # 120 —Å–µ–∫ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
                whisper_http_client = httpx.Client(timeout=whisper_timeout)
                self.whisper_client = OpenAI(
                    api_key=openai_api_key,
                    http_client=whisper_http_client
                )
                print("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Whisper API (OpenAI)")
            else:
                print("‚ö†Ô∏è USE_WHISPER_API=true, –Ω–æ OPENAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ü–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—ã–π Whisper.")
                use_whisper_api = False
        
        if not use_whisper_api:
            # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ Whisper
            try:
                from backend.ml.services.whisper_service import LocalWhisperService
                
                # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
                model_size = os.getenv("WHISPER_MODEL_SIZE", "base")  # tiny, base, small, medium, large-v2, large-v3
                device = os.getenv("WHISPER_DEVICE", "cpu")  # cpu –∏–ª–∏ cuda
                compute_type = os.getenv("WHISPER_COMPUTE_TYPE", "int8")  # int8, int8_float16, float16, float32
                download_root = os.getenv("WHISPER_DOWNLOAD_ROOT")  # –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
                
                self.local_whisper = LocalWhisperService(
                    model_size=model_size,
                    device=device,
                    compute_type=compute_type,
                    download_root=download_root
                )
                print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω—ã–π Whisper (–º–æ–¥–µ–ª—å: {model_size}, —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device})")
                # –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ LocalWhisperService
            except ImportError as e:
                print(f"‚ö†Ô∏è faster-whisper –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {e}")
                print("‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Whisper API...")
                self.local_whisper = None
                # Fallback –Ω–∞ API –µ—Å–ª–∏ –ª–æ–∫–∞–ª—å–Ω—ã–π –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω
                openai_api_key = os.getenv("OPENAI_API_KEY")
                if openai_api_key:
                    whisper_timeout = httpx.Timeout(120.0, connect=30.0)
                    whisper_http_client = httpx.Client(timeout=whisper_timeout)
                    self.whisper_client = OpenAI(
                        api_key=openai_api_key,
                        http_client=whisper_http_client
                    )
                    print("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Whisper API (fallback)")
                else:
                    print("‚ùå Whisper –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: –Ω–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏ –Ω–µ—Ç OPENAI_API_KEY")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ Whisper: {e}")
                import traceback
                traceback.print_exc()
                self.local_whisper = None
                # Fallback –Ω–∞ API –µ—Å–ª–∏ –ª–æ–∫–∞–ª—å–Ω—ã–π –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω
                openai_api_key = os.getenv("OPENAI_API_KEY")
                if openai_api_key:
                    whisper_timeout = httpx.Timeout(120.0, connect=30.0)
                    whisper_http_client = httpx.Client(timeout=whisper_timeout)
                    self.whisper_client = OpenAI(
                        api_key=openai_api_key,
                        http_client=whisper_http_client
                    )
                    print("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Whisper API (fallback)")
                else:
                    print("‚ùå Whisper –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: –æ—à–∏–±–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏ –Ω–µ—Ç OPENAI_API_KEY")
        self.quick_responses = {
            '–ø—Ä–∏–≤–µ—Ç': '–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –Ø –≤–∞—à –±–∏–∑–Ω–µ—Å-–ø–æ–º–æ—â–Ω–∏–∫. –ó–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥—É, —Ñ–∏–Ω–∞–Ω—Å–∞–º, —é—Ä–∏—Å–ø—Ä—É–¥–µ–Ω—Ü–∏–∏ –∏–ª–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—é –±–∏–∑–Ω–µ—Å–æ–º.',
            '—Å–ø–∞—Å–∏–±–æ': '–ü–æ–∂–∞–ª—É–π—Å—Ç–∞! –û–±—Ä–∞—â–∞–π—Ç–µ—Å—å, –µ—Å–ª–∏ –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è –µ—â—ë –ø–æ–º–æ—â—å.',
            '–ø–æ–º–æ—â—å': '–Ø –∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É—é –ø–æ –≤–æ–ø—Ä–æ—Å–∞–º –±–∏–∑–Ω–µ—Å–∞: –º–∞—Ä–∫–µ—Ç–∏–Ω–≥, —Ñ–∏–Ω–∞–Ω—Å—ã, —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã, —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ. –ó–∞–¥–∞–π—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å!',
        }
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤
        try:
            self.encoding = tiktoken.get_encoding("cl100k_base")
        except:
            self.encoding = None

    def get_quick_response(self, question: str) -> Optional[str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –±—ã—Å—Ç—Ä—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤"""
        return self.quick_responses.get(question.lower().strip())

    def count_tokens(self, text: str) -> int:
        """–ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ"""
        if not self.encoding:
            return len(text.split())  # fallback
        return len(self.encoding.encode(text))

    def prepare_conversation_messages(
            self,
            system_prompt: str,
            user_question: str,
            conversation_history: List[Dict] = None,
            max_tokens: int = 3000
    ) -> List[Dict]:
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è LLM —Å —É—á–µ—Ç–æ–º –∏—Å—Ç–æ—Ä–∏–∏ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ —Ç–æ–∫–µ–Ω–∞–º
        """
        messages = [{"role": "system", "content": system_prompt}]
        current_tokens = self.count_tokens(system_prompt)

        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if conversation_history:
            # –ò–¥–µ–º –æ—Ç —Å–∞–º—ã—Ö —Å—Ç–∞—Ä—ã—Ö –∫ –Ω–æ–≤—ã–º, –Ω–æ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–æ —Ç–æ–∫–µ–Ω–∞–º
            history_messages = []
            history_tokens = 0

            for msg in reversed(conversation_history):  # –Ω–∞—á–∏–Ω–∞–µ–º —Å —Å–∞–º—ã—Ö –Ω–æ–≤—ã—Ö
                if hasattr(msg, 'role') and hasattr(msg, 'content'):
                    # –ï—Å–ª–∏ —ç—Ç–æ SQLAlchemy –æ–±—ä–µ–∫—Ç
                    role = msg.role
                    content = msg.content
                elif isinstance(msg, dict) and 'role' in msg and 'content' in msg:
                    # –ï—Å–ª–∏ —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å
                    role = msg['role']
                    content = msg['content']
                else:
                    continue

                message_tokens = self.count_tokens(content)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø—Ä–µ–≤—ã—Å–∏–º –ª–∏ –ª–∏–º–∏—Ç
                if current_tokens + history_tokens + message_tokens > max_tokens:
                    break

                history_messages.insert(0, {"role": role, "content": content})
                history_tokens += message_tokens

            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é
            messages.extend(history_messages)
            current_tokens += history_tokens

        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_tokens = self.count_tokens(user_question)
        messages.append({"role": "user", "content": user_question})
        current_tokens += user_tokens

        print(
            f"üìä –¢–æ–∫–µ–Ω—ã: —Å–∏—Å—Ç–µ–º–∞={self.count_tokens(system_prompt)}, –∏—Å—Ç–æ—Ä–∏—è={current_tokens - self.count_tokens(system_prompt) - user_tokens}, –≤–æ–ø—Ä–æ—Å={user_tokens}, –≤—Å–µ–≥–æ={current_tokens}")

        return messages

    def generate_response(
            self,
            system_prompt: str,
            user_question: str,
            conversation_history: List[Dict] = None,
            max_history_tokens: int = 3000
    ) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM —Å —É—á–µ—Ç–æ–º –∏—Å—Ç–æ—Ä–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π

        Args:
            system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            user_question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            conversation_history: –ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π (–∏–∑ –ë–î)
            max_history_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏

        Returns:
            –û—Ç–≤–µ—Ç –æ—Ç LLM –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        """
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Å —É—á–µ—Ç–æ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ —Ç–æ–∫–µ–Ω–∞–º
            messages = self.prepare_conversation_messages(
                system_prompt,
                user_question,
                conversation_history,
                max_history_tokens
            )

            completion = self.client.chat.completions.create(
                extra_headers={
                    "HTTP-Referer": "http://localhost:5000",
                    "X-Title": "Business Assistant",
                },
                model="tngtech/deepseek-r1t2-chimera:free",
                messages=messages,
                temperature=0.5,
                max_tokens=1000  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –æ—Ç–≤–µ—Ç
            )

            if not completion.choices or len(completion.choices) == 0:
                raise ValueError("LLM –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")

            response = completion.choices[0].message.content
            
            if not response:
                raise ValueError("LLM –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ")

            return response

        except ValueError as e:
            raise
        except Exception as e:
            error_message = str(e)
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–∫–∏ 401 - –Ω–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á
            if "401" in error_message or "User not found" in error_message or "authentication" in error_message.lower():
                raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á OpenRouter. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é OPENROUTER_API_KEY.")
            elif "rate limit" in error_message.lower() or "quota" in error_message.lower() or "429" in error_message:
                raise ValueError("–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
            elif "timeout" in error_message.lower():
                raise ValueError("–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
            else:
                raise ValueError(f"–û—à–∏–±–∫–∞ LLM: {error_message}")

    def generate_response_with_context(
            self,
            system_prompt: str,
            context_messages: List[Dict],
            user_question: str
    ) -> str:
        """
        –£—Å—Ç–∞—Ä–µ–≤—à–∏–π –º–µ—Ç–æ–¥ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        """
        return self.generate_response(system_prompt, user_question, context_messages)

    def summarize_conversation(self, conversation_history: List[Dict]) -> str:
        """
        –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –¥–ª–∏–Ω–Ω–æ–π –±–µ—Å–µ–¥—ã –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

        Args:
            conversation_history: –ü–æ–ª–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è –±–µ—Å–µ–¥—ã

        Returns:
            –ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –±–µ—Å–µ–¥—ã
        """
        if not conversation_history or len(conversation_history) < 5:
            return ""

        try:
            summary_prompt = """
            –°—É–º–º–∞—Ä–∏–∑—É–π —Å–ª–µ–¥—É—é—â—É—é –±–µ—Å–µ–¥—É –≤ 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö, –≤—ã–¥–µ–ª–∏–≤ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è.
            –°–æ—Ö—Ä–∞–Ω–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –±—É–¥—É—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤.

            –ë–µ—Å–µ–¥–∞:
            """

            # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —á–∞—Å—Ç—å –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
            recent_history = conversation_history[-10:]  # –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π

            conversation_text = ""
            for msg in recent_history:
                if hasattr(msg, 'role') and hasattr(msg, 'content'):
                    role = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if msg.role == "user" else "–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç"
                    conversation_text += f"{role}: {msg.content}\n"
                elif isinstance(msg, dict):
                    role = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if msg.get('role') == "user" else "–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç"
                    conversation_text += f"{role}: {msg.get('content', '')}\n"

            summary_prompt += conversation_text

            completion = self.client.chat.completions.create(
                extra_headers={
                    "HTTP-Referer": "http://localhost:5000",
                    "X-Title": "Business Assistant",
                },
                model="tngtech/deepseek-r1t2-chimera:free",
                messages=[
                    {"role": "system", "content": "–¢—ã –ø–æ–º–æ–≥–∞–µ—à—å —Å—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞—Ç—å –±–µ—Å–µ–¥—ã."},
                    {"role": "user", "content": summary_prompt}
                ],
                temperature=0.3,
                max_tokens=300
            )

            return completion.choices[0].message.content

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {e}")
            return ""

    def get_conversation_stats(self, conversation_history: List[Dict]) -> Dict:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –±–µ—Å–µ–¥–µ

        Args:
            conversation_history: –ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        total_messages = len(conversation_history)
        user_messages = 0
        assistant_messages = 0
        total_tokens = 0

        for msg in conversation_history:
            if hasattr(msg, 'role') and hasattr(msg, 'content'):
                role = msg.role
                content = msg.content
            elif isinstance(msg, dict):
                role = msg.get('role', '')
                content = msg.get('content', '')
            else:
                continue

            if role == 'user':
                user_messages += 1
            elif role == 'assistant':
                assistant_messages += 1

            total_tokens += self.count_tokens(content)

        return {
            'total_messages': total_messages,
            'user_messages': user_messages,
            'assistant_messages': assistant_messages,
            'estimated_tokens': total_tokens,
            'conversation_ratio': user_messages / total_messages if total_messages > 0 else 0
        }

    def transcribe_audio(self, audio_bytes: bytes, filename: str = "audio.webm", language: str = "ru") -> str:
        """
        –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ –ª–æ–∫–∞–ª—å–Ω—ã–π Whisper –∏–ª–∏ API
        
        Args:
            audio_bytes: –ë–∞–π—Ç—ã –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞
            filename: –ò–º—è —Ñ–∞–π–ª–∞ (–Ω—É–∂–Ω–æ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–∞)
            language: –Ø–∑—ã–∫ –∞—É–¥–∏–æ (ru, en, etc.)
            
        Returns:
            –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π Whisper –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        if self.local_whisper:
            try:
                # –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∑–∏—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–∞–π–º–∞—É—Ç –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ (–º–∞–∫—Å–∏–º—É–º 60 —Å–µ–∫—É–Ω–¥)
                import threading
                
                result = [None]
                error = [None]
                
                def transcribe_with_timeout():
                    try:
                        result[0] = self.local_whisper.transcribe(audio_bytes, language=language)
                    except Exception as e:
                        error[0] = e
                
                thread = threading.Thread(target=transcribe_with_timeout, daemon=True)
                thread.start()
                thread.join(timeout=60)  # –¢–∞–π–º–∞—É—Ç 60 —Å–µ–∫—É–Ω–¥
                
                if thread.is_alive():
                    print("‚è±Ô∏è –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –ø—Ä–µ–≤—ã—Å–∏–ª–∞ —Ç–∞–π–º–∞—É—Ç (60 —Å–µ–∫), –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ API...")
                    raise TimeoutError("–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –ø—Ä–µ–≤—ã—Å–∏–ª–∞ —Ç–∞–π–º–∞—É—Ç")
                
                if error[0]:
                    raise error[0]
                
                if result[0] is None:
                    raise ValueError("–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
                
                return result[0]
                
            except (TimeoutError, ValueError, Exception) as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏: {e}")
                import traceback
                traceback.print_exc()
                # Fallback –Ω–∞ API –µ—Å–ª–∏ –ª–æ–∫–∞–ª—å–Ω—ã–π –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª
                if self.whisper_client:
                    print("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ Whisper API...")
                    try:
                        audio_file = io.BytesIO(audio_bytes)
                        audio_file.name = filename
                        transcript = self.whisper_client.audio.transcriptions.create(
                            model="whisper-1",
                            file=audio_file,
                            language=language
                        )
                        print("‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —á–µ—Ä–µ–∑ Whisper API —É—Å–ø–µ—à–Ω–∞")
                        return transcript.text
                    except Exception as api_error:
                        print(f"‚ùå –û—à–∏–±–∫–∞ Whisper API: {api_error}")
                        raise ValueError(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏: {str(e)}. API —Ç–∞–∫–∂–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {str(api_error)}")
                else:
                    raise ValueError(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏: {str(e)}")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º Whisper API –µ—Å–ª–∏ –ª–æ–∫–∞–ª—å–Ω—ã–π –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
        if self.whisper_client:
            # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª–æ–≤—ã–π –æ–±—ä–µ–∫—Ç –∏–∑ –±–∞–π—Ç–æ–≤
            audio_file = io.BytesIO(audio_bytes)
            audio_file.name = filename
            
            try:
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Whisper API
                transcript = self.whisper_client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language=language
                )
                
                return transcript.text
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ Whisper API: {e}")
                raise ValueError(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏: {str(e)}")
        else:
            raise ValueError(
                "Whisper –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. "
                "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ faster-whisper (pip install faster-whisper) "
                "–∏–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ OPENAI_API_KEY –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è API"
            )

    def analyze_image(self, image_base64: str, prompt: str, mime_type: str = "image/jpeg") -> str:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ LLM —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π vision
        
        Args:
            image_base64: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ base64 (–±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ data:)
            prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            mime_type: MIME —Ç–∏–ø –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (image/jpeg, image/png –∏ —Ç.–¥.)
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        """
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º data URL –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            image_data_url = f"data:{mime_type};base64,{image_base64}"
            
            system_prompt = "–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –û–ø–∏—Å—ã–≤–∞–π —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ–¥—Ä–æ–±–Ω–æ –∏ —Ç–æ—á–Ω–æ. –ï—Å–ª–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç, –∏–∑–≤–ª–µ–∫–∏ –µ–≥–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é. –ï—Å–ª–∏ —ç—Ç–æ –≥—Ä–∞—Ñ–∏–∫ –∏–ª–∏ –¥–∏–∞–≥—Ä–∞–º–º–∞, –æ–ø–∏—à–∏ –¥–∞–Ω–Ω—ã–µ."
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–æ—Ä–º–∞—Ç –¥–ª—è vision API: content –∫–∞–∫ –º–∞—Å—Å–∏–≤ –æ–±—ä–µ–∫—Ç–æ–≤
            messages = [
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": prompt
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": image_data_url
                            }
                        }
                    ]
                }
            ]
            
            # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å vision-–º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ OpenRouter
            # –ú–Ω–æ–≥–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ OpenRouter –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç vision, –Ω–∞–ø—Ä–∏–º–µ—Ä:
            # - openai/gpt-4-vision-preview
            # - google/gemini-pro-vision
            # - anthropic/claude-3-opus
            # - qwen/qwen-vl-plus
            
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ OpenRouter —Å vision-–º–æ–¥–µ–ª—å—é
            try:
                completion = self.client.chat.completions.create(
                    extra_headers={
                        "HTTP-Referer": "http://localhost:5000",
                        "X-Title": "Business Assistant",
                    },
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π vision
                    # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç vision, –ø–æ–ø—Ä–æ–±—É–µ–º OpenAI API
                    model="openai/gpt-4o-mini",  # GPT-4o-mini –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç vision
                    messages=messages,
                    temperature=0.7,
                    max_tokens=1000
                )
                
                if completion.choices and len(completion.choices) > 0:
                    result = completion.choices[0].message.content
                    if result:
                        print(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —á–µ—Ä–µ–∑ OpenRouter")
                        return result
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —á–µ—Ä–µ–∑ OpenRouter vision: {e}")
                # Fallback –Ω–∞ OpenAI API –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
                pass
            
            # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º OpenAI API –Ω–∞–ø—Ä—è–º—É—é, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
            openai_api_key = os.getenv("OPENAI_API_KEY")
            if openai_api_key:
                try:
                    openai_timeout = httpx.Timeout(60.0, connect=30.0)
                    openai_http_client = httpx.Client(timeout=openai_timeout)
                    openai_client = OpenAI(
                        api_key=openai_api_key,
                        http_client=openai_http_client
                    )
                    
                    completion = openai_client.chat.completions.create(
                        model="gpt-4o-mini",  # GPT-4o-mini –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç vision
                        messages=messages,
                        temperature=0.7,
                        max_tokens=1000
                    )
                    
                    if completion.choices and len(completion.choices) > 0:
                        result = completion.choices[0].message.content
                        if result:
                            print(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —á–µ—Ä–µ–∑ OpenAI API")
                            return result
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —á–µ—Ä–µ–∑ OpenAI API: {e}")
            
            # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
            return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω OPENAI_API_KEY –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π vision."
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            import traceback
            traceback.print_exc()
            return f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}"